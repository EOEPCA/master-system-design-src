[[mainResourceManagement,Resource Management]]
= Resource Management

The role of the Resource Management domain is the storage, discovery and access to resources in the Exploitation Platform. In this context, resources primarily refers to data and processing assets. The concerns of processing assets are addressed in the ‘Processing & Chaining’ domain area. Thus, Resource Management focuses primarily on the provision of data within the EP.

Storage is largely taken care of by the Resource Tier upon which the Exploitation Platform is hosted. The role of the Exploitation Platform is to ensure that the data can be accessed through common data access protocols based upon open standards.

This is important for:

* the end-user wishing to access data directly
* processing services accessing data for input/output
* other federated Exploitation Platforms accessing each other’s data and services through well understood interfaces

To exploit the services of the Platform, users need to discover available data, obtain detailed collection/product information, including the ability to visualise the data in the platform. This applies to data held within the platform, data added by end-users and data produced as the result of processing operations within the platform.

[#img_resourceUseCase,reftext='{figure-caption} {counter:figure-num}']
.Resource Management Use Case
image::use-cases-data.png[width=1000,align="center"]

Processing services and applications are also platform resources that are stored in artefact repositories and must be discoverable by users, including the information required by users to exploit the service. It is assumed that users will store their software artefacts in external public repositories such as DockerHub, GitHub, etc. In the future, it may be necessary for an Exploitation Platform to provide such repository services to its users. Discovery of processing services and applications is met though the ‘Processing & Chaining’ domain area by the provision of an Application Catalogue. See <<procAppCatalogue>> for more details.

The inventory and presentation of resources to users must be organised in such a way as to facilitate the discovery and usage of resources in other federated Exploitation Platforms. For example, users must be able to discover data and services in other EPs in order to construct and execute workflows that span multiple federated EPs.

Access to resources must be controlled according to the privileges afforded to the logged in user, and appropriate hooks must be established into the EPs accounting and billing subsystems. Thus, the Resource Management services must be implemented according to the approach defined by User Management for authorisation, accounting and billing.

In addition to the resource holding of the underlying resource tier, the EP maintains a User Workspace in which each user is able to maintain specific data/services of interest to them, and also provides a place to hold results of processing operations. The User Workspace should be provided as a building block of the system that provides this personal inventory. Moreover, the concept can be extended to define Group Workspaces to create a place for sharing and collaboration.

A Data Ingestion component abstracts the interface to the underlying Resource Tier storage, ensures that incoming data is formatted in accordance with defined standards, is supported by appropriate metadata and directed towards the appropriate dataset collection.

The main components comprising the Resource Management domain are illustrated in <<img_resourceOverview>>:

* Data Catalogue
* Data Access Services
* Data Access Gateway
* Data Access Library
* Data Ingestion
* Workspace

[#img_resourceOverview,reftext='{figure-caption} {counter:figure-num}']
.Resource Management Overview
image::resource-overview.png[width=1000,align="center"]

To some degree, the role of these components is to provide an integration of the Exploitation Platform to the Resource Tier, by providing public services that bridge to the underlying data supply.

== Data Catalogue

The Catalogue provides the user the capability to discover data/products by browse/search, and to obtain details on specific data/products discovered.

=== Metadata Organisation

The data is organised into Collections, typically representing a dataset. Each collection is composed of multiple granules as files. The catalogue metadata follows a similar organisation and allows the user to discover the data in natural sympathy with this data organisation. Hence, the metadata is presented at the following levels:

Browse Metadata (collection)::
Browse metadata is defined at the collection/dataset level. It typically uses ISO19115 records to describe the high-level collection information, such as title, description, spatial**/temporal coverage, list of variables available, access rights, T&Cs, etc. +
**For collections, the spatial coverage is often full-earth.

Discovery Metadata (product)::
Discovery metadata is defined for each granule (file) comprising the collection. This typically includes information such as file-type(s), spatial/temporal coverage, variable, data access (download) method(s). Much of this information can be obtained from the headers of the individual files – depending on file-type. Thus, the Discovery metadata can in-part be populated automatically from the underlying files.

Archive Metadata (file)::
Archive metadata refers to the information that is available in the file header. As described above this can be extracted and published into the Discovery metadata of the catalogue.

=== Example Usage with OpenSearch

This metadata model can be exploited, for example, using OpenSearch:

* Initial search is made at the collection level to discover collections/dataset of interest.
* Subsequent OpenSearch requests can then be made to drill-down into a specific collection to discover and obtain details regarding the granules.
* Once discovered, the granules can then be exploited by the user, for example as input to a processing request, or downloaded.
* Facets can be applied to both the Browse and Discovery metadata, to supported facetted search at both levels.

=== OpenSearch

For the Exploitation Platform, OpenSearch is used with the OGC extensions and recommendations:

* OpenSearch GEO: OpenSearch Geo and Time Extensions <<OS-GEO-TIME>>
* OpenSearch EO: OGC OpenSearch Extension for Earth Observation <<OS-EO>>
* OGC EO Dataset Metadata GeoJSON(-LD) Encoding Standard <<GEOJSON-LD>>
* OGC OpenSearch-EO GeoJSON(-LD) Response Encoding Standard <<GEOJSON-LD-RESP>>

The CEOS OpenSearch Best Practise <<CEOS-OS-BP>> provides a blueprint – this is the approach adopted by the FedEO project.

=== Resource Types

Perhaps the most challenging aspect of this is that the Catalogues for both Data and Processing-Services must facilitate the proper construction of processing tasks, to ensure there is a proper match of the data types expected as input to the processing. This extends into the construction of workflows where the data types output by a processing task must match the supported inputs of the next task in the chain. The Catalogue must have a rich and consistent metadata model for both Data and Processing-Services in order to achieve these goals.

=== Data Access
There is also a link between the way the data is described in the Catalogue and how it is accessed by the consumers of the data. This links to the Data Access Services (e.g. WMS. WCS, WFS, etc.) provided by the EP, and the way in which the access links are encoded into the Catalogue. These links must be usable by the data consumers which could be processing services, or users downloading the data.

=== EP Catalogue vs Infrastructure Catalogue

The Exploitation Platform is designed to be hosted in a compute environment that is close to the data of interest. This means that the typical deployment is made to the likes of DIAS, Public Cloud (such as AWS), or National Research Infrastructure (such as CEDA/JASMIN) – that provide the Resources-tier/infrastructure upon which the EP relies.

The Resources-tier provides virtual ICT-infrastructure and data. It is common that the Resources-tier provides their own Catalogue to support the data hosted within. However, the Resource-tier catalogue may not present a Catalogue interface that is in accordance with the approach advocated by the Exploitation Platform Common Architecture, or it may not provide a data catalogue at all. It is therefore incumbent upon the EP to define a catalogue architecture that takes account of these possibilities. Additionally, the EP will maintain its own ‘value-added’ and user contributed data that must be catalogued at the level of the exploitation platform. <<img_catalogueAggregation>> illustrates.

[#img_catalogueAggregation,reftext='{figure-caption} {counter:figure-num}']
.Catalogue Aggregation
image::catalogue-aggregation.png[width=1000,align="center"]

We wish the exploitation platform to expose a public catalogue that provides both the Browse (collection) and Discovery (product) views:

* In the case where the Resource-tier provides these in a way that is conformant with the architecture then these can be relied upon directly for the exploitation platform
* In the case where the Resource-tier provides only a suitable Product catalogue, then the Collection catalogue must be provided by the EP, with the granule queries being directed to the back-end catalogue. Alternatively, this could be achieved by harvesting the Resource-tier product catalogue into the EP catalogue.
* Alternatively, the EP may provide a Catalogue-shim to ensure that an existing Resource-tier catalogue conforms to the interface demands of the open architecture
* Otherwise, the EP must provide all catalogue aspects.

The important point is to ensure that the EP presents interfaces that conform to its defined open standards, and is able to take measures to ensure this is the case. From the perspective of the user of the Exploitation Platform a single Data Catalogue end-point is most desirable. The EP web interface can present a consolidated user view in the case of multiple catalogue end-points. A similar consolidation approach can be applied by the EP programmatic API, which can present a single end-point on behalf of the back-end data catalogues.

=== Federated Discovery

In order that a user is able to discover data/services of interest in a federated network of Exploitation Platforms, an approach to Catalogue federation must be established between collaborating platforms.

[#img_catalogueFederation,reftext='{figure-caption} {counter:figure-num}']
.Catalogue Federation
image::catalogue-federation.png[width=1000,align="center"]

As illustrated in <<img_catalogueFederation>> there are a number of possible approaches:

* Gateway – A central proxy
* Centralised – Central mirror
* Distributed - Catalogues mirror each other

Further analysis is required to understand these options, their applicability and impact on the Common Architecture.

== Data Access Services

The Exploitation Platform provides access to data through public services based upon Open Standards, for the consumption by end-users and other federated platforms.

The primary services provided by an Exploitation Platform should include:

* OGC Web Map Service (WMS)
* OGC Web Coverage Service (WCS)
* OGC Web Feature Service (WFS)
* Services provided by Resource Tier:
** AWS S3 Object Store
** Swift Object Store (OpenStack)

Other services that may also be considered include:

* WebDAV
* FTP
* CDMI

The integration of these services into the data-layer of the hosting Resource Tier relies upon the Data Access Gateway providing an infrastructure agnostic interface for accessing the underlying data holding.

[[resourcesDataAccessGateway,Data Access Gateway]]
== Data Access Gateway

The EO datasets are stored according to the underlying storage technology of the infrastructure Resource Tier. The storage interface presented is not under the control of the Exploitation Platform.

The role of the Data Access Gateway is to provide an abstraction layer on top of the underlying storage to present a well-defined storage interface to the other components of the Exploitation Platform.

The main EP components that require data access are:

* Processing services and applications: stage-in/out of data/results
* Platform Data Access Services (WMS,WCS,etc.): access to datasets
* Ingestion: storage of ingested data

In the EP system design, these services are designed to be deployed as containers through Kubernetes. This presents the possibility that some aspects of the Data Access Gateway can be met by the facilities offered by Kubernetes volumes. Access to underlying data is provided through volumes that are mounted into the container. Kubernetes volumes have native support for a number of common storage technologies (such as AWS EBS, Cinder), however these tend to be block rather than object storage.

The Gateway must provide a data bridge between the EP components and the Resource Tier. It fills the gap in the data access capabilities of a given a given service/application, and provides a common data access interface that such components can target in their implementation. Thus, the Gateway should provide a standard set of service interfaces to include:

* AWS S3 Object Store
* Swift Object Store (OpenStack)
* OGC data access services: Web Map Service (WMS), Web Coverage Service (WCS), Web Feature Service (WFS)

In providing these standard services to the other EP components, the Data Access Gateway must implement the data access interface to the infrastructure Resource Tier storage.

[[resourcesDAL,Data Access Library]]
== Data Access Library (DAL)

In addition to the Data Access Gateway, which operates as an internal service, the Data Access Library (DAL) is provided specifically as a point of integration for processing services and applications. The Data Access Library provides an abstraction of the interface to the data, with bindings for common languages (including python, Javascript) and presents a standard programmatic semantic for accessing the data from within the processing service codebase.

The Data Access Library can provide an abstraction at two levels:

Protocol abstraction::
Standard programmatic semantics are provided for accessing the data (i.e. CRUD operations on data granules), that is agnostic of the underlying platform storage data access protocols. This is a lower level interface that should be applicable to all use cases.

Data Model abstraction::
A common object model is defined with programmatic semantics, which provides a higher-level abstraction of the data that hides the details of the underlying storage, files and file-formats. The abstraction accesses and parses the underlying data to present data structure representations within the language bindings. Such an object model would likely be applicable to some, but not all, use cases. In cases where this approach is not applicable, then protocol abstraction provides the fall-back option.

Thus, processing services and applications can be implemented in a ‘portable’ way that is agnostic to the platform resource-tier storage technology.

Specific implementations of the DAL can be made to abstract the data access layer for a given Exploitation Platform. The library offered to the processing service at runtime must implement the specific data access interface to the resource-tier storage. Hence, the library should not be ‘hard-coded’ into the processor application package (Docker image). The Processing Framework must support the ability to 'plugin' an alternative (platform-specific) implementation of the DAL dynamically at processor execution time. It may be possible to develop a 'generic' Data Access Library by implementation against the standard (internal) interface provided by the Data Access Gateway. In this case, the platform-specifics regarding data access are borne entirely by the Data Access Gateway.

== Data Ingestion

Presents a standard interface to the EP components, whilst transparently interfacing with the infrastructure Resource Tier.

Performs the following steps:

* Authorisation check
* Quota check
* Metadata extraction
* Preview generation
* Format conversion
* Storage PUT
* Catalogue PUT
* Trigger notifications

Ingestion raises notifications for the following events:

•	Raise indicators to users (visual, emails, etc.)
•	Trigger systematic actions in other EP services (e.g. systematic processing)

== Workspace

The Workspace provides a service to users through which they can organise data/processing-services that are of current interest to them, they are currently working on, and to organise results of processing executed, Research Objects, etc.

This concept can be extended to create a Group Workspace for sharing and collaboration.

It may be possible to model the Workspace as a Catalogue, in which the browse/discover access privilege is limited either to an individual user (personal workspace) or a group of collaborating users (group workspace):

* OpenSearch interface for read
* What interface for add, update, delete ?
